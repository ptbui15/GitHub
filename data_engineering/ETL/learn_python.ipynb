{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building & Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phong\n",
      "36\n",
      "100\n",
      "53\n",
      "5\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from assets import myModule as my\n",
    "\n",
    "phong = my.Person(\"Phong\", 36)\n",
    "\n",
    "print(phong.name)\n",
    "print(phong.age)\n",
    "phong.changeAge(100)\n",
    "print(phong.age)\n",
    "\n",
    "steve = my.Student(\"Steve\", 53)\n",
    "\n",
    "print(steve.age)\n",
    "print(my.testVariable)\n",
    "my.testFunc(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Person', 'Student', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'testArgs', 'testFunc', 'testVariable']\n",
      "Phong\n",
      "test1\n",
      "test2\n"
     ]
    }
   ],
   "source": [
    "from assets import myModule as my\n",
    "print(dir(my))\n",
    "my.testArgs(var1 = phong, test='test1', test2 = 'test2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "3\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#your_function_name = lambda inputs : output\n",
    "a = 1\n",
    "b = 2\n",
    "sum = lambda x,y : x + y\n",
    "c = sum(a,b)\n",
    "print(c)\n",
    "\n",
    "\n",
    "l = [2,4,7,3,14,19]\n",
    "for i in l:\n",
    "    odd = lambda x : x%2==1\n",
    "    if(odd(i)==True):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While loop\n",
    "\n",
    "value = 1\n",
    "while value <= 5:\n",
    "    print(value, \"Loop\")\n",
    "    value += 1\n",
    "\n",
    "# for loop\n",
    "for i in range(10):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_name(input_name):\n",
    "    if input_name == 'Phong':\n",
    "        print (\"yup\")\n",
    "    else:\n",
    "        print(\"nope\")\n",
    "\n",
    "name = input(\"What's your name?\")\n",
    "print(\"Hello\", name)\n",
    "confirm_name(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testList = [\"apple\", 12, 24, \"nope\"]\n",
    "\n",
    "print(testList[0]+\" \"+str(testList[2]))\n",
    "\n",
    "testList.append(\"yes\")\n",
    "testList.remove(\"apple\")\n",
    "testList.insert(1,\"ok\")\n",
    "\n",
    "print(testList[-1])\n",
    "print(testList[0])\n",
    "\n",
    "print(testList)\n",
    "\n",
    "for i in testList:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map, Filter, Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_pets = ['alfred', 'tabitha', 'william', 'arla']\n",
    "uppered_pets = list(map(str.upper, my_pets))\n",
    "print(uppered_pets)\n",
    "\n",
    "# Same as below\n",
    "my_strings = ['a', 'b', 'c', 'd', 'e']\n",
    "my_numbers = [1, 2, 3, 4, 5]\n",
    "results = list(zip(my_strings, my_numbers))\n",
    "print(results)\n",
    "\n",
    "# Same as above\n",
    "my_strings = ['a', 'b', 'c', 'd', 'e']\n",
    "my_numbers = [1, 2, 3, 4, 5]\n",
    "results = list(map(lambda x, y: (x, y), my_strings, my_numbers))\n",
    "print(results)\n",
    "\n",
    "\n",
    "# Filter\n",
    "# Python 3\n",
    "scores = [66, 90, 68, 59, 76, 60, 88, 74, 81, 65]\n",
    "def is_A_student(score):\n",
    "    return score > 75\n",
    "over_75 = list(filter(is_A_student, scores))\n",
    "print(over_75)\n",
    "\n",
    "# Reduce\n",
    "# Python 3\n",
    "from functools import reduce\n",
    "numbers = [3, 4, 6, 9, 34, 12]\n",
    "\n",
    "def custom_sum(first, second):\n",
    "    return first + second\n",
    "\n",
    "result = reduce(custom_sum, numbers)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from assets import golfScores as gs\n",
    "\n",
    "\n",
    "# Retrieve tournament -> saves to golf.csv\n",
    "#gs.tournamentData()\n",
    "\n",
    "# Read from created .csv\n",
    "df = pd.read_csv('golf.csv')\n",
    "#print(df.head())\n",
    "\n",
    "# Filter rows based off column, return all columns\n",
    "filtered = df[df['total'] < -10]\n",
    "#print(filtered.head())\n",
    "\n",
    "# Filter rows based off column, return subset of columns\n",
    "filtered = df.loc[df[\"position\"] == 'T3', [\"lastName\",\"strokes\"]]\n",
    "#print(filtered.head())\n",
    "\n",
    "# New column derived from existing column\n",
    "filtered['newColumn'] = (filtered['lastName']) + \"_\" + \"new\"\n",
    "#print(filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching SQL -> Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crime = pd.read_csv('data/crime.csv')\n",
    "\n",
    "# SELECT * FROM crime WHERE col1 = 'a' and col2 = 'b'\n",
    "filtered = crime.loc[((crime['NEIGHBORHOOD_ID'] == 'valverde') & (crime['IS_CRIME'] == 1))]\n",
    "\n",
    "# SELECT col1, col2 FROM crime WHERE col3 = 'a'\n",
    "filtered2 = crime.loc[((crime['NEIGHBORHOOD_ID'] == 'valverde') & (crime['IS_CRIME'] == 1)),['OFFENSE_CATEGORY_ID', 'OFFENSE_TYPE_ID']]\n",
    "\n",
    "# SELECT COUNT(*) FROM crime\n",
    "print(crime.loc[((crime['NEIGHBORHOOD_ID'] == 'valverde') & (crime['IS_CRIME'] == 1))].count())\n",
    "\n",
    "# SELECT count(*), col1 FROM crime GROUP BY col1\n",
    "print(crime.loc[((crime['NEIGHBORHOOD_ID'] == 'valverde') & (crime['IS_CRIME'] == 1)),['OFFENSE_CATEGORY_ID', 'OFFENSE_TYPE_ID']].groupby('OFFENSE_TYPE_ID').size())\n",
    "\n",
    "# SELECT DISTINCT col1, col2 FROM crime\n",
    "filtered3 = crime.drop_duplicates(['NEIGHBORHOOD_ID','OFFENSE_CATEGORY_ID'])[['NEIGHBORHOOD_ID','OFFENSE_CATEGORY_ID']]\n",
    "\n",
    "\n",
    "# SELECT MIN(col1) FROM crime WHERE col2 = 'a';\n",
    "crime.loc[crime['NEIGHBORHOOD_ID']=='valverde',['GEO_LON']].min()\n",
    "\n",
    "# SELECT * FROM crime where col1 IN (a,b,c)\n",
    "cities = ['valverde', 'hampden']\n",
    "filtered_df = crime[crime['NEIGHBORHOOD_ID'].isin(cities)]\n",
    "filtered4 = filtered_df[['NEIGHBORHOOD_ID','GEO_LON']]\n",
    "\n",
    "\n",
    "# SELECT column_name(s) FROM table1 LEFT JOIN table2 ON table1.column_name = table2.column_name; \n",
    "\n",
    "join_df = pd.DataFrame({'nbhr':['valverde', 'hampden'], 'col':[1,2]})\n",
    "\n",
    "    # Matching column names\n",
    "    # left_join_df = filtered4.merge(join_df, how='inner', on='NEIGHBORHOOD_ID')\n",
    "\n",
    "    # Different column names\n",
    "left_join_df = filtered4.merge(join_df, how='inner', left_on='NEIGHBORHOOD_ID', right_on='nbhr')\n",
    "left_join_df = left_join_df.loc[:,['NEIGHBORHOOD_ID', 'GEO_LON','col']]\n",
    "\n",
    "\n",
    "# SELECT column_name(s) FROM table1 INNER JOIN table2 ON table1.column_name = table2.column_name;\n",
    "join_df = pd.DataFrame({'nbhr':['valverde'], 'col':[1]})\n",
    "inner_join_valverde_df = filtered4.merge(join_df, how='inner', left_on='NEIGHBORHOOD_ID', right_on='nbhr')\n",
    "inner_join_valverde_df = inner_join_valverde_df.loc[:,['NEIGHBORHOOD_ID', 'GEO_LON','col']]\n",
    "\n",
    "join_df = pd.DataFrame({'nbhr':['hampden'], 'col':[2]})\n",
    "inner_join_hampden_df = filtered4.merge(join_df, how='inner', left_on='NEIGHBORHOOD_ID', right_on='nbhr')\n",
    "inner_join_hampden_df = inner_join_hampden_df.loc[:,['NEIGHBORHOOD_ID', 'GEO_LON','col']]\n",
    "\n",
    "# SELECT column_name(s) FROM table1 UNION\n",
    "# SELECT column_name(s) FROM table2;\n",
    "union_df = pd.concat([inner_join_valverde_df, inner_join_hampden_df])\n",
    "\n",
    "#INSERT INTO table_name (column1, column2, column3, ...)\n",
    "#VALUES (value1, value2, value3, ...);\n",
    "new_values_df = pd.DataFrame({'NEIGHBORHOOD_ID':['lebanon'], 'GEO_LON':[100], 'col':[3]})\n",
    "insert_df = pd.concat([union_df, new_values_df])\n",
    "\n",
    "#UPDATE table_name\n",
    "#SET column1 = value1, column2 = value2, ...\n",
    "#WHERE condition;\n",
    "insert_df.loc[insert_df['NEIGHBORHOOD_ID'] == 'lebanon', 'col'] = 6\n",
    "\n",
    "\n",
    "# DELETE FROM table_name WHERE condition;\n",
    "# DELETE hampmden\n",
    "insert_df = insert_df.loc[~(insert_df['NEIGHBORHOOD_ID'] == 'hampden'), :]\n",
    "#insert_df = insert_df[insert_df['NEIGHBORHOOD_ID'] != 'hampden]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAll(\n",
    "    [\n",
    "        ('spark.app.name', 'pysparktest'),\n",
    "        ('spark.master', 'spark://localhost:7077'),\n",
    "        ('spark.executor.memory', \"512m\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Spark dataframe from a pandas (can't get Spark to read csv yet)\n",
    "df = pd.read_csv('data/2015-summary.csv')\n",
    "flightdata2015 = spark.createDataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling is a mechanism Spark uses to redistribute the data across different executors and even across machines\n",
    "spark.conf.set('spark.sql.shuffle.partitions','5')\n",
    "flightdata2015.sort('count').take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightdata2015.createOrReplaceTempView('flight_data_2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay = spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME, count(1) FROM flight_data_2015 GROUP BY DEST_COUNTRY_NAME\"\"\")\n",
    "sqlWay = spark.sql(\"\"\"SELECT max(count) FROM flight_data_2015\"\"\")\n",
    "sqlWay = spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME, sum(count) as destination_total FROM flight_data_2015 GROUP BY DEST_COUNTRY_NAME ORDER BY sum(count) DESC\"\"\")\n",
    "sqlWay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "flightdata2015.groupBy('DEST_COUNTRY_NAME').sum('count').withColumnRenamed('sum(count)' ,'destination_total').sort(desc('destination_total')).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 3.8.9 Package Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "from bokeh.models import HoverTool, WheelZoomTool\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook\n",
    "output_notebook()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.init_notebook_mode()\n",
    "t = np.linspace(-1, 1.2, 2000)\n",
    "x = (t**3) + (0.3 * np.random.randn(2000))\n",
    "y = (t**6) + (0.3 * np.random.randn(2000))\n",
    "\n",
    "colorscale = ['#7A4579', '#D56073', 'rgb(236,158,105)', (1, 1, 0.2), (0.98,0.98,0.98)]\n",
    "\n",
    "fig = ff.create_2d_density(\n",
    "    x, y, colorscale=colorscale,\n",
    "    hist_color='rgb(255, 237, 222)', point_size=3\n",
    ")\n",
    "\n",
    "py.iplot(fig, filename='histogram_subplots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "x = 2 + 2*np.random.standard_normal(n)\n",
    "y = 2 + 2*np.random.standard_normal(n)\n",
    "\n",
    "p = figure(title=\"Hexbin for 500 points\", match_aspect=True,\n",
    "           tools=\"wheel_zoom,pan,reset\", background_fill_color='#440743')\n",
    "p.grid.visible = False\n",
    "\n",
    "r, bins = p.hexbin(x, y, size=0.5, hover_color=\"pink\", hover_alpha=0.8)\n",
    "\n",
    "p.circle(x, y, color=\"white\", size=1)\n",
    "\n",
    "p.add_tools(HoverTool(\n",
    "    tooltips=[(\"count\", \"@c\"), (\"(q,r)\", \"(@q, @r)\")],\n",
    "    mode=\"mouse\", point_policy=\"follow_mouse\", renderers=[r]\n",
    "))\n",
    "\n",
    "p.toolbar.active_scroll = p.select_one(WheelZoomTool)\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('dataengineering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4524c90d178d43c4fa8acfe45a1d5a7a8fec32e07b66a762b58c14d08737da56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
